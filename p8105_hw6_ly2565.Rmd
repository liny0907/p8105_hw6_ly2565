---
title: "p8105_hw6_ly2565"
author: "Lin Yang"
date: "11/29/2021"
output: github_document
---

```{r, setup, include = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

### Load and clean the dataset for regression analysis
```{r, message = FALSE, warning = FALSE}
birthweight_df = 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4", "other" = "8", "unknown" = "9"),
    malform = as.logical(malform),
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4", "other" = "8", "unknown" = "9"))
  

birthweight_df 
```


### Check for missing values
```{r}
map(birthweight_df, ~sum(is.na(.)))
```
There are no missing values in the dataset. 

### Propose a regression model for birthweight

I built a regression model using a model selection approach called *Backward Elimination* which starts with all predictors in the model and then removes one predictor with the highest p value at a time until all p values are smaller than 0.05. 
```{r}
#fit regression model using all predictors
fit_all = lm(bwt ~ ., data = birthweight_df)
summary(fit_all)

#pnumlbw and pnumsga show NA, check unique values in the two columns
unique(pull(birthweight_df, pnumlbw))
unique(pull(birthweight_df, pnumsga))

#no pnumlbw
step1 = update(fit_all, . ~ . -pnumlbw)
summary(step1)
#no pnumsga
step2 = update(step1, . ~ . -pnumsga)
summary(step2)
#no wtgain
step3 = update(step2, . ~ . -wtgain)
summary(step3)
#no frace
step4 = update(step3, . ~ . -frace)
summary(step4)
#no malform
step5 = update(step4, . ~ . -malform)
summary(step5)
#no ppbmi
step6 = update(step5, . ~ . -ppbmi)
summary(step6)
#no momage
step7 = update(step6, . ~ . -momage)
summary(step7)
#no menarche
step8 = update(step7, . ~ . -menarche)
summary(step8)
#no mrace
step9 = update(step8, . ~ . -mrace)
summary(step9)
```
Using the Backward Elimination approach, I first removed variables, `pnumlbw`, `pnumsga`, `wtgain` which returned NA for all estimates. The reason why `wtgain` showed NA might be that it highly correlated with other variables, like `delwt`: mother's weight at delivery and `ppwt`: mother's pre-pregnancy weight. In terms of `pnumlbw` and `pnumsga`, they returned NA because there were only values of 0 in the two columns. 

After removing all non-significant predictors, I fitted a regression model for baby birthweight based on predictors: `babysex`, `bhead`, `blength`, `delwt`, `fincome`, `gaweeks`, `mheight`, `parity`, `ppwt`, and `smoken`. 
```{r}
model1 = lm(bwt ~babysex + bhead + blength + delwt + fincome + gaweeks + mheight + parity + ppwt + smoken, data = birthweight_df)

summary(model1)
broom::tidy(model1)
```

Make a plot of model residuals against fitted values.
```{r, message = FALSE, dpi = 300}
birthweight_df %>% 
  add_predictions(model1) %>% 
  add_residuals(model1) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.2) +
  geom_smooth(color = "red", method = "lm", se = FALSE) +
  labs(
    x = "Predicted Values",
    y = "Residuals",
    title = "Residuals vs Predicted Values"
  )
```

Based on this plot, residual values appear to be evenly distributed around 0, indicating constant variance of residuals. However, there are two predicted values less than 0, which may be outliers, and there are two obvious outliers with residuals over 2000. 


### Fit the other two models

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
model2 = lm(bwt ~blength + gaweeks, data = birthweight_df)
summary(model2)
broom::tidy(model2)

model3 = lm(bwt ~bhead + blength + babysex + 
                 bhead * blength + bhead * babysex + blength * babysex +
                 bhead * blength * babysex, data = birthweight_df)
summary(model3)
broom::tidy(model3)
```

### Compare the three models in terms of cross validation
```{r, warning = FALSE}
cv_df =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    model1 = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + parity + ppwt + smoken, data = .x)),
    model2 = map(train, ~lm(bwt ~blength + gaweeks, data = .x)),
    model3 = map(train, ~lm(bwt ~bhead + blength + babysex + 
                 bhead * blength + bhead * babysex + blength * babysex +
                 bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y))) %>% 
  select(-train, -test, -c(model1:model3))

cv_df 
```

Make a boxplot showing rmse distribution across 3 models.
```{r, dpi = 300}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_boxplot(aes(fill = model), alpha = 0.5) +
  labs(
    x = "Model",
    y = "RMSE",
    title = "Distribution of RMSE across Models"
  )
```

The boxplot indicates that model1 has the lowest prediction error distribution, and model2 has the highest one. This suggests that my model is the best fit for birthweight among the three models. 

## Problem 2

### Load the 2017 Central Park weather data

```{r, message = FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

weather_df
```

### Bootstrapping

Draw 5000 bootstrap samples.
```{r}
boot_strap_df = 
  weather_df %>% 
  bootstrap(n = 5000)

boot_strap_df
```

Produce an estimate of r squared for each bootstrap sample and plot the distribution of estimates.
```{r, dpi = 300}
r_squared_results = 
  boot_strap_df %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(.id, r.squared)

r_squared_results

r_squared_results %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    x = "R Squared Estimates", 
    y = "Density",
    title = "Distribution of R Squared Estimates")
```

Calculate 95% confidence interval for r squared. 
```{r}
r_squared_results %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)) %>% 
  knitr::kable()
```
R squared estimates appear to be normally distributed with a mean of `r round(mean(pull(r_squared_results, r.squared)), 3)` and sd of `r round(sd(pull(r_squared_results, r.squared)), 3)`. There are no obvious outliers. The 95% confidence interval for r squared is (0.894, 0.927). 


Produce an estimate of log(beta0 * beta1) for each bootstrap group and plot the distribution of estimates.
```{r, dpi = 300}
log_results = 
  boot_strap_df %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>% 
  rename(
    beta0 = `(Intercept)`, 
    beta1 = tmin) %>% 
  mutate(log = log(beta0 * beta1)) 
 
log_results

log_results %>% 
  ggplot(aes(x = log)) +
  geom_density() +
  labs(
    x = "Log(beta0 * beta1) Estimates",
    y = "Density",
    title = "Distribution of Estimates of Log(beta0 * beta1)")
```

Calculate 95% confidence interval for log(beta0 * beta1).
```{r}
log_results %>% 
  summarize(
    ci_lower = quantile(log, 0.025),
    ci_upper = quantile(log, 0.975)) %>% 
  knitr::kable()
```
Log(beta0 * beta1) estimates appear to be normally distributed with a mean of `r round(mean(pull(log_results, log)), 3)` and sd of `r round(sd(pull(log_results, log)), 3)`. There are no obvious outliers. The 95% confidence interval for log(beta0 * beta1) is (1.967, 2.059). 



