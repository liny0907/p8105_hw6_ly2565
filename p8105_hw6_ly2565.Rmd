---
title: "p8105_hw6_ly2565"
author: "Lin Yang"
date: "11/29/2021"
output: github_document
---

```{r, setup, include = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

### Load and clean the dataset for regression analysis
```{r, message = FALSE}
birthweight_df = 
  read_csv("data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))

birthweight_df
```

### Check for missing values
```{r}
map(birthweight_df, ~sum(is.na(.)))
```
There are no missing values in the dataset. 

### Propose a regression model for birthweight

fit regression using all predictors
```{r}
mult.fit = lm(bwt ~ ., data = birthweight_df)
summary(mult.fit)

step1 = update(mult.fit, . ~ . -pnumlbw)
summary(step1)

step2 = update(step1, . ~ . -pnumsga)
summary(step2)

step3 = update(step2, . ~ . -wtgain)
summary(step3)

step4 = update(step3, . ~ . -ppbmi)
summary(step4)

step5 = update(step4, . ~ . -malform)
summary(step5)

step6 = update(step5, . ~ . -frace)
summary(step6)

step7 = update(step6, . ~ . -menarche)
summary(step7)

```



```{r}
model1 = lm(bwt ~babysex + bhead + blength + delwt + fincome + gaweeks + mheight + momage + mrace + parity + ppwt + smoken, data = birthweight_df)

summary(model1)
broom::tidy(model1)
```

Make a plot of model residuals against fitted values.
```{r, warning = FALSE, dpi = 300}
birthweight_df %>% 
  add_predictions(model1) %>% 
  add_residuals(model1) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(color = "red", method = "lm", se = FALSE)
```

### Fit the other two models

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
model2 = lm(bwt ~blength + gaweeks, data = birthweight_df)
summary(model2)
broom::tidy(model2)

model3 = lm(bwt ~bhead + blength + babysex + 
                 bhead * blength + bhead * babysex + blength * babysex +
                 bhead * blength * babysex, data = birthweight_df)
summary(model3)
broom::tidy(model3)
```

### Compare the three models in terms of cross validation
```{r, warning = FALSE}
cv_df =
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    model1 = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + momage + mrace + parity + ppwt + smoken, data = .x)),
    model2 = map(train, ~lm(bwt ~blength + gaweeks, data = .x)),
    model3 = map(train, ~lm(bwt ~bhead + blength + babysex + 
                 bhead * blength + bhead * babysex + blength * babysex +
                 bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y)))

cv_df 
```

Make a boxplot showing rmse distribution across 3 models.
```{r, dpi = 300}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_boxplot(aes(fill = model), alpha = 0.5)
```
The boxplot indicates that model3 has the lowest prediction error distribution, and model1 has the highest one. This suggests that model3 is the best fit for birthweight among the three models. 

## Problem 2

### Load the 2017 Central Park weather data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

weather_df
```

### Bootstrapping

Draw 5000 bootstrap samples.
```{r}
boot_strap_df = 
  weather_df %>% 
  bootstrap(n = 5000)

boot_strap_df
```

Produce estimates of r squared for each bootstrap sample and plot the distribution of estimates.
```{r}
r_squared_results = 
  boot_strap_df %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(.id, r.squared)

r_squared_results

r_squared_results %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    x = "R Squared Estimates", 
    y = "Density",
    title = "Distribution of R Squared Estimates")
```

Calculate 95% confidence interval for r squared. 
```{r}
r_squared_ci = 
  r_squared_results %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)) %>% 
  knitr::kable()
```
R squared estimates appear to be normally distributed with a mean of `r round(mean(pull(r_squared_results, r.squared)))` and sd of `r round(sd(pull(r_squared_results, r.squared)))`. There are no obvious outliers. The 95% confidence interval for r squared is `r r_squared_ci`. 


Produce an estimate of log(beta0 * beta1) for each bootstrap group and plot the distribution of estimates.
```{r}
log_results = 
  boot_strap_df %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>%
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>% 
  rename(
    beta0 = `(Intercept)`, 
    beta1 = tmin) %>% 
  mutate(log = log(beta0 * beta1)) 
 
log_results

log_results %>% 
  ggplot(aes(x = log)) +
  geom_density() +
  labs(
    x = "Log(beta0 * beta1) Estimates",
    y = "Density",
    title = "Distribution of Estimates of log(beta0 * beta1)")
```

Calculate 95% confidence interval for log(beta0 * beta1).
```{r}
log_ci = 
  log_results %>% 
  summarize(
    ci_lower = quantile(log, 0.025),
    ci_upper = quantile(log, 0.975)) %>% 
  knitr::kable()
```
Log(beta0 * beta1) estimates appear to be normally distributed with a mean of `r round(mean(pull(log_results, log)), 3)` and sd of `r round(sd(pull(log_results, log)))`. There are no obvious outliers. The 95% confidence interval for log(beta0 * beta1) is `r log_ci`. 



